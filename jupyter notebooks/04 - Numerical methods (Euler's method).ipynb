{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40b404f",
   "metadata": {},
   "source": [
    "# Numerical methods\n",
    "\n",
    "$$\n",
    " \\newcommand{d}{\\,{\\rm d}}\n",
    " \\def\\vc#1{\\mathbf{\\boldsymbol{#1}}}     % vector\n",
    " \\def\\tn#1{{\\mathbb{#1}}}\n",
    " \\def\\Real{{\\rm\\bf R}}\n",
    " \\def\\prtl{\\partial}\n",
    "$$\n",
    "\n",
    "As we have already noted, the analytical solution can only be found for particular ODE systems. \n",
    "A general solution procedure is only available for linear systems with constant coefficients \n",
    "and even here we are limited to small systems for which, we are able to find eigenvalues.\n",
    "Numerical methods make it possible to solve general systems of ODE approximately.\n",
    "The error could be made small, but ussually increase with simulation time.\n",
    "Some natural processes are described by equations, where a small perturbation of \n",
    "the initial condition leads to large differences after certain time or even to qualitatively \n",
    "different solutions. An example would be a ball on the edge. The equation describing the weather also belong\n",
    "to this category with makes reliable long-term forcasts intractable.\n",
    "\n",
    "As any system of ODE of any order can be converted to a system of equations of the first order, we can limit ourselves to the investigation of numerical methods for first-order equations, namely the initial problem:\n",
    "$$\n",
    "\\dot{\\vc y}=\\vc f(t,\\vc y),\\qquad\\vc y(0)=\\vc \\xi.\n",
    "$$\n",
    "We restrict ourselves to the initial time $\\tau =0$ and solutions only for positive times $t>0$. Time reversion\n",
    "could be done by change of the time variable $t = -s$.\n",
    "\n",
    "Furthermore, in order to ensure the existence of a unique solution to the problem (see the Pickard theorem),\n",
    "we will require the following properties of the right-hand side function $f$:\n",
    "\n",
    "- vector function $\\vc f$ is a continuous function on the strip $(t,\\vc x) \\in \\langle a,b\\rangle\\times \\Real^n$\n",
    "\n",
    "- $\\vc f$ is Lipschit on this strip in the form $\\vc x$ with a constant $L$ independent of $t$, i.e.\n",
    "  \n",
    "  $$\n",
    "    \\|\\vc f(t, \\vc x) - \\vc f(t, \\vc y)\\| \\le L \\|\\vc x - \\vc y\\|, \\qquad \\text{ for all } t\\ in\\langle a,b     \\rangle,\\ x,\\,y \\in \\Real^n\n",
    "  $$\n",
    "\n",
    "The values of the solution and the function of the right side are from the space $\\Real^n$, on which we will consider any given norm $\\|\\cdot\\|$, e.g. Euclidean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf8b15",
   "metadata": {},
   "source": [
    "## Explicit Euler's Method\n",
    "\n",
    "In context of numerical methods, we approximate unknown function $y(t)$ by a sequence of values $y_i$, $i=1,\\dots, N$ at particular set of discrete times $t_i$. As the simples case let us choose discrete times regularly:\n",
    "\n",
    "$$\n",
    "t_i=a+ih,\\quad i=\\in I_N=\\{0,1,\\dots, N\\},\n",
    "$$\n",
    "\n",
    "kde $N=T/h$ for the end time $T$. The $h$ is named the \"integration step\" or just \"step\" of the method.\n",
    "\n",
    "The simplest method follwos by simple approximation of the derivative by a difference:\n",
    "\n",
    "$$\n",
    "   \\vc y'(t_{i+1}) \\approx \\frac{\\vc y_{i+1} - \\vc y_{i}}{h} = \\vc f(t_i, \\vc y_i)   \n",
    "$$   \n",
    "\n",
    "Alternatively, we can the Taylor expansion (at time $t=0$) to calculate the solution:\n",
    "\n",
    "$$\n",
    "  \\vc y(h) = \\vc y(0) + h \\vc y'(0) + O(h^2) = \\vc y_0 + h \\vc f(0, \\vc y_0) + O(h^ 2).\n",
    "$$\n",
    "\n",
    "We get Euler's method if we neglect the term $O(h^2)$ in the previous formula. This gives us the approximate value of the solution $\\vc y(h) \\approx \\vc y_1$ at time $t_1=h$. \n",
    "\n",
    "Performin the same for the initial time $t = h$, we get the value of the approximate solution at time \n",
    "$t_2=2h$:\n",
    "\n",
    "$$\n",
    "  \\vc y(2h) \\approx \\vc y_2 = \\vc y_1 + h \\vc f(h, \\vc y_1).\n",
    "$$\n",
    "\n",
    "In general, the approximate solution at time $t_{i+1}=(i+1)h$ is given by the recurrent formula:\n",
    "\n",
    "$$\n",
    "   \\vc y_{i+1} = \\vc y_i + h f(t_i, \\vc y_i),\\qquad t_i=ih,\\qquad i>0.\n",
    "$$\n",
    "\n",
    "This is how we gradually get the values of the approximate solution $y_i$ in times $t_i$, for $i=1,2,\\dots$\n",
    "Thus, at each step we construct a tangent to the exact solution starting at the point $(t_i, \\vc y_i)$\n",
    "and until time $t_{n+1}$ we approximate the solution with this tangent, viz. Fig Euler aprox.\n",
    "\n",
    "From the discrete sequaence of values, we can reconstruct the piecewise linear function as:\n",
    "$$\n",
    "   \\vc{\\tilde y}(t) = \\frac{\\vc y_{i+1}(t - t_i) + \\vc y_i(t_{i+1}-t)}{h},\\qquad \\text {on } [t_i, t_{i+1}].\n",
    "$$\n",
    "\n",
    "## Numerical Errors\n",
    "\n",
    "Usage of an approximate solution introduces an error (global error) between exact and approximate solution, which is result of propagation an accumulation of errors at individual steps (local errror). This can be directly related to the error of the numerical scheme. Moreover we have to deal with error due to usage of inexact representation of the real numbers in computer (inexact arithmetic). Let us describe these times of errors in more detail.\n",
    "\n",
    "In Figure Euler approx, we see the exact solution (green) of the equation $y'=2y$ for the initial condition $(t_0, y_0)$. The red line depicts the piecewise linear approximate solution.\n",
    "\n",
    "\n",
    "<center><img src=\"numerical_errors.png\" alt=\"discrete errors\" width=\"600\"/></center>\n",
    "<font size= “1”> Fig. Euler approx: Exact solution (green) and approximate solution (red) calculated by the explicit Euler method. Local errors $d_i$ (orange) and global error $e_3 (black, right)$. </font>\n",
    "\n",
    "\n",
    "Difference between these two functions is:\n",
    "\n",
    "**Global error** $\\vc e_i$ at time $t_i$ is the difference between the exact and approximate solution after $i$ steps of the method:\n",
    "$$\n",
    "    \\vc e_i = \\vc y(t_i) - \\vc y_i.\n",
    "$$\n",
    "while both solutions satisfy the same initial condition $\\vc y(t_0)=\\vc y_0$.\n",
    "\n",
    "In a more general sense, we can understand the global error as the function \n",
    "$\\vc e(t) = \\vc y(t) - \\vc{\\tilde y}(t)$.\n",
    "\n",
    "The global error contains (but not simply sum) of local errors at individual steps.\n",
    "The **local error** $\\vc d_i$ is difference between the exact and the approximate solution after one step.\n",
    "For the first step, it is equivalent to the global error\n",
    "$\\vc d_1=\\vc e_1=\\vc y(t_1; t_0, \\vc y_0) - \\vc y_1$. \n",
    "For the general step $i$, we have to consider the exact solution $\\vc y(t; t_{i-1}, \\vc y_{i-1})$,\n",
    "which starts from the value of the approximate solution $\\vc y_{i-1}$ at the previous time $t_{i-1}$, these solutions are marked as dashed blue line in the Figure.\n",
    "\n",
    "\n",
    "**Local error** $\\vc d_i$ at time $t_i$ is the difference between the exact and approximate solution after one step of the method,\n",
    "\n",
    "$$\n",
    "   \\vc d_i = \\vc y(t_i; t_{i-1}, \\vc y_{i-1}) - \\vc y_i,\n",
    "$$\n",
    "\n",
    "where the exact solution satisfies the initial condition $\\vc y(t_{i-1}) = \\vc y_{i-1}$.\n",
    "\n",
    "Local error is closely related to the *local discretization error*.\n",
    "\n",
    "TBD\n",
    "\n",
    "To define it, we first introduce the difference operator of Euler's method:\n",
    "\\[\n",
    " \\mathcal{L}_h \\vc y(t_i) = \\frac{\\vc y(t_i) - \\vc y(t_{i-1})}{h} - \\vc f(t_{i-1}, \\vc y(t_{i-1})), \\quad \\text{for }i>0.\n",
    "\\]\n",
    "\\begin{definition}\n",
    " \\df{Local discretization error} $\\vc{\\tau}_i$ at time $t_i$ is the accuracy with which the exact solution\n",
    " $y(t_i; t_{i-1}, y_{i-1})$ satisfies the difference equation of the method:\n",
    " \\[\n",
    "   \\vc{\\tau}_i = \\mathcal{L}_h \\vc y(t_i)\n",
    " \\]\n",
    "\\end{definition}\n",
    "\n",
    "In the case of the explicit Euler method, we have\n",
    "\\[\n",
    "  \\vc d_i = \\vc y(t_i; t_{i-1}, \\vc y_{i-1}) - \\vc y_i = \\vc y(t_i) - \\Big\\{\\vc y_{i-1} + h \\vc f(t_{i-1}, \\vc y_{i-1})\\Big\\} = h\\mathcal{L}_h \\vc y(t_i)\n",
    "\\]\n",
    "and thus $\\vc \\tau_i = \\vc d_i/h$. For other methods, the relationship between local error and local discretization error can be more complex.\n",
    "                                                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e79c8",
   "metadata": {},
   "source": [
    "\\begin{definition}\n",
    " We say that a method is consistent if it holds\n",
    " \\[\n",
    "   \\lim_{h\\to 0} \\max_{i\\in I_N} \\norm{\\vc \\tau_i} = 0.\n",
    " \\]\n",
    " The method is consistent of order $p$ if $\\norm{\\vc\\tau_i} = O (h^p)$ holds for all $i=1,\\dots, N$, i.e.\n",
    " \\[\n",
    "        \\norm{\\vc \\tau_i} \\le C h^p\n",
    " \\]\n",
    "for some constant $C$ and all sufficiently small $h$.\n",
    "\\end{definition}\n",
    "\n",
    "\\begin{definition}\n",
    " We say that the method is convergent of order $p$ if the global error converges when calculating the numerical solution on a fixed interval $t \\in [0,T]$\n",
    " with $h$ decreasing to zero:\n",
    " \\[\n",
    "    \\lim_{h\\to 0} \\max_{i\\in I_N} \\norm{\\vc e_i} = 0,\n",
    " \\]\n",
    " If $\\max_{i<N} \\norm{\\vc e_i} = O(h^p)$, we say that the method converges to order $p$.\n",
    "\\end{definition}\n",
    "\n",
    "\n",
    "\\begin{table}\n",
    "\\centering\n",
    "\\begin{tabular}{|c|c|c|c|c|}\n",
    "clay\n",
    "$i$ & $t_i$ & $y_i$ & $d_i$ & $e_i$\\\\\n",
    "clay\n",
    "0 & 0.0000 & 1.0000 & 0.0000 & 0.0000\\\\\n",
    "clay\n",
    "1 & 0.0010 & 0.9000 & 0.0048 & 0.0048\\\\\n",
    "clay\n",
    "2 & 0.0020 & 0.8100 & 0.0044 & 0.0087\\\\\n",
    "clay\n",
    "3 & 0.0030 & 0.7290 & 0.0039 & 0.0118\\\\\n",
    "clay\n",
    "4 & 0.0040 & 0.6561 & 0.0035 & 0.0142\\\\\n",
    "clay\n",
    "5 & ​​0.0050 & 0.5905 & 0.0032 & 0.0160\\\\\n",
    "clay\n",
    "6 & 0.0060 & 0.5314 & 0.0029 & 0.0174\\\\\n",
    "clay\n",
    "7 & 0.0070 & 0.4783 & 0.0026 & 0.0183\\\\\n",
    "clay\n",
    "8 & 0.0080 & 0.4305 & 0.0023 & 0.0189\\\\\n",
    "clay\n",
    "9 & 0.0090 & 0.3874 & 0.0021 & 0.0191\\\\\n",
    "clay\n",
    "10 & 0.0100 & 0.3487 & 0.0019 & 0.0192\\\\\n",
    "clay\n",
    "\\hline\\end{tabular}\n",
    "\\label{table:solutions}\n",
    "\\caption{Solutions and errors using the Euler method, $\\lambda=-100$, $h=0.001$.}\n",
    "\\end{table}\n",
    "\n",
    "\n",
    "\n",
    " \\begin{table}\n",
    "\\centering\n",
    "\\begin{tabular}{|c|c|c|c|}\n",
    "clay\n",
    "$h$ & $i=T/h$ & $y_i$ & $e_i$\\\\\n",
    "clay\n",
    "1.00e-3 & 1.00e+2 & 2.66e-5 & 1.88e-5\\\\\n",
    "clay\n",
    "1.00e-4 & 1.00e+3 & 4.32e-5 & 2.23e-6\\\\\n",
    "clay\n",
    "1.00e-5 & 1.00e+4 & 4.52e-5 & 2.27e-7\\\\\n",
    "clay\n",
    "1.00e-6 & 1.00e+5 & 4.54e-5 & 2.27e-8\\\\\n",
    "clay\n",
    "\\hline\\end{tabular}\n",
    "\\label{table:convergence}\n",
    "\\caption{Dependence of the solution error on the time step, $T=0.1$, $\\lambda=-100$.}\n",
    "\\end{table}\n",
    "\n",
    "\n",
    "\\begin{example}\n",
    "\\label{ex:decay}\n",
    "Consider the initial task:\n",
    "\\[\n",
    "  y'=\\lambda y,\\qquad y(0) =1.\n",
    "\\]\n",
    "Its exact solution is $y(t) = e^{\\lambda t}$. The prescription for $y_n$ according to the Euler method \\eqref{eq:Euler_method} is\n",
    "\\[\n",
    "   y_i = (1+ h\\lambda)y_{i-1},\\qquad i>0,\\qquad y_0=1.\n",
    "\\]\n",
    "By choosing $\\lambda=-100$ and $h=0.001$, we get\n",
    "\\[\n",
    "    y_i=0.9y_{i-1}, \\qquad i>0,\\qquad y_0=1\n",
    "\\]\n",
    "In table \\ref{table:reseni} are the first ten steps\n",
    "Euler's methods. We see that the local error $d_i$ does not increase, on the contrary it decreases, but the global error $e_i$\n",
    "still growing. Table \\ref{table:convergence} shows the dependence of the global error on the size of the time step $h$.\n",
    "We see that $e_i$ decreases linearly depending on $h$, so it is a first-order convergent method.\n",
    "\n",
    "\n",
    "Let us try to prove this observation in general for the explicit Euler method. By definition of local error, we have:\n",
    "\\begin{equation}\n",
    "  \\label{eq:local_err}\n",
    "  \\vc d_i = \\vc y(t_i;t_{i-1}, y_{i-1}) - \\vc y_i = \\vc y(t_i) - \\vc y_{i-1} - h \\vc f( t_{i-1}, \\vc y_{i-1})\n",
    "\\end{equation}\n",
    "For the exact solution, we use the Taylor expansion:\n",
    "\\[\n",
    "    \\vc y(t_i)=\\vc y(t_{i-1})+ h \\vc y'(t_{i-1})+\\frac{h^2}{2}\\vc y''(\\ xi_i),\\quad \\text{for some }\\xi_i \\in (t_{i-1}, t_i).\n",
    "\\]\n",
    "Now we substitute in \\eqref{eq:local_err} and further use the equation for $y'(t_{i-1})$, since for local errors we assume\n",
    "$y(t_{i-1})=y_{i-1}$, we get:\n",
    "\\[\n",
    "    \\vc d_i = \\vc y(t_{i-1})+h\\vc y '(t_{i-1}) + \\frac{h^2}{2}\\vc y''(\\xi_i) - \\vc y(t_{i-1}) - h\\vc f(t_{i-1}, \\vc y_{i-1}) = \\frac{h^2}{2}\\vc y''( \\xi_i).\n",
    "\\]\n",
    "From there we also determine the local discretization error: $\\vc \\tau_i = \\vc d_i/h = \\frac{h}{2}\\vc y''(\\xi_i)$ and therefore it is explicit\n",
    "Euler's consistent method of order $1$.\n",
    "\n",
    "TODO: global error and convergence\n",
    "\\end{example}\n",
    "\n",
    "\\begin{theorem}\\label{Theorem 2.2}\n",
    "Let $\\vc y$ be the solution of the initial problem with a right-hand side $\\vc f$ satisfying the assumptions of the Picard theorem \\ref{thm::Picard} with the Lipschitz constant $L$.\n",
    "Furthermore, let the solution $\\vc y$ have two continuous derivatives on the interval $[ 0, T]$. Then it holds for the approximate solution $\\vc y_i$ calculated by the explicit Euler method\n",
    "\\begin{equation}\\label{estimateEul}\n",
    "\\norm{\\vc y_i - \\vc y(t_i)} \\leq h M(t_i) E_L(t_i), i=0,\\dots,n,\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{displaymath}\n",
    "M(t_i) = \\frac 12 \\max_{s\\in [0,t_i]} \\norm{\\ddot{\\vc{y}}(s)},\\qquad\n",
    "E_L(t)=\\left\\{\\begin{array}{ll}\n",
    "                \\frac{e^{Lt}-1}{L}&\\mbox{for } L>0\\\\\n",
    "                t&\\mbox{for } L=0\n",
    "              \\end{array}\\right. ,\n",
    "\\end{displaymath}\n",
    "\\end{theorem}\n",
    "The formula (\\ref{estimateEul}) expresses the {\\em a priori estimate} of the error of Euler's method,\n",
    "if we know the function $M(t)$. However, without knowing the solution, we do not know this function.\n",
    "However, we get the information from Theorem \\ref{Theorem2.2} that the speed of convergence is Euler's\n",
    "method is $h$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
