{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67cfa36d",
   "metadata": {},
   "source": [
    "# Linear ODR Systems\n",
    "\n",
    "$$\n",
    " \\newcommand{d}{\\,{\\rm d}}\n",
    " \\def\\vc#1{\\mathbf{\\boldsymbol{#1}}}     % vector\n",
    " \\def\\tn#1{{\\mathbb{#1}}}\n",
    " \\def\\Real{{\\rm\\bf R}}\n",
    " \\def\\prtl{\\partial}\n",
    "$$\n",
    "\n",
    "There is no general procedure for solving differential equations, just as there is no general procedure for integration. No solution in the closed form (formula) is available for most ODE and their systems. However\n",
    "such procedure and solution in a closed form exists for the linear systems of ODE. Structure of the solutions to the linear systems and procedure(s) to find them is topic of this chapter. \n",
    "\n",
    "Linear systems are important as an approximation to more general ODE and also as the testbad for the numerical methods that we will dicuss later. Let us explain the approimation. Conisder a system of ODEs with a smooth but non-linear right-hand side $\\vc f(t, \\vc x)$.  Using the Taylor expansion of $\\vc f$ separately for $t$ and $\\vc x$ we obtain its linear approximation around point $(t_0, \\vc x_0)$:\n",
    "\n",
    "$$\n",
    "   f_i(t_0 + s, \\vc x_0 + \\vc h) = f_i(t_0, \\vc x_0) + \\frac{\\prtl f_i}{\\prtl t}(t_0,\\vc x_0)s \n",
    "   + \\sum_j \\frac{ \\prtl f_i}{\\prtl x_j}(t_0,\\vc x_0) h_j + O(\\delta^2)\n",
    "$$\n",
    "for small deviations of $s, h_j \\le \\delta$. Using the more compact vector notation we have:\n",
    "\n",
    "$$\n",
    "  \\vc f(t_0 + s, \\vc x_0 + \\vc h) \\approx \\tn A \\vc h + \\vc b,\\quad \\vc b(s)=\\vc f(t_0, \\vc x_0) \n",
    "  + \\prtl_{t} \\vc f(t_0, \\vc x_0) s,\n",
    "$$\n",
    "\n",
    "where $\\tn A =\\nabla_{\\vc x} \\vc f(t_0, \\vc x_0)$\n",
    "is the matrix of partial derivatives with respect to $\\vc x$.\n",
    "Here $\\tn A$ is even time-independent, which is a special class of linear ODE systems with *constant coefficients*\n",
    " for which a general solution procedure is available.\n",
    "\n",
    "In general, we say that a system $\\dot{\\vc x}=\\vc f(t,\\vc x)$ is *linear* if the function $\\vc f$ is linear, i.e.\n",
    "\n",
    "$$\n",
    "\\vc f(t,\\vc x) = \\tn A(t) \\vc x + \\vc b(t),\n",
    "$$\n",
    "\n",
    "where $\\tn A(t)$, called *the system matrix*, is a matrix function of time defined on the interval $I$ \n",
    "and $\\vc b(t)$, *the right-hand side*, is a vector function of time defined on the interval $I$.   \n",
    "A linear system is called *homogeneous* if $\\vc b(t)=0$ for all $t\\in I$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adccca0",
   "metadata": {},
   "source": [
    "## Existence and uniqueness\n",
    "We will now show that there is a unique solution for linear systems.\n",
    "If $\\tn A(t)$ and $\\vc b(t)$ are continuous functions on the open interval $I$, then $\\vc f(t, \\vc x)$\n",
    "is continuous in the variable $t$ on the interval $I$. Its partial derivatives in the variable $\\vc x$\n",
    "\n",
    "$$\n",
    "  \\frac{\\prtl\\vc f_i}{\\prtl x_j}(t,\\vc x) = a_{ij}(t)\n",
    "$$\n",
    "\n",
    "do not depend on $\\vc x$ and due to continuity will be bounded on any closed subinterval $J\\subset I$, see the [extreme value theorem](https://en.wikipedia.org/wiki/Extreme_value_theorem).\n",
    "Thus, the function $\\vc f(t,\\vc x)$ is Lipschitz in $\\vc x$ for all times of $J\\times \\Real^n$.\n",
    "Since $J$ is an arbitrary closed subinterval of $I$, we can extend the solution to the entire interval of $I$.\n",
    "Then, as a result of the existence-uniqueness theorem, we get the following theorem about the existence and uniqueness of solutions of linear equations.\n",
    "\n",
    "**Theorem**\n",
    "Let the matrix function $\\tn A$ and the vector function $\\vc b$ be continuous on\n",
    "closed interval $I$. Then for each initial point $(\\tau,\\vc\\xi)\\in I\\times R^n$ has\n",
    "Cauchy problem\n",
    "$$\n",
    "\\dot {\\vc x}(t)={\\tn A}(t)\\vc x(t)+{\\vc b}(t),\\qquad \\vc x(\\tau)=\\vc\\xi\n",
    "$$\n",
    "exactly one solution $\\vc x(t;\\tau,\\vc\\xi)$ which is defined on the whole\n",
    "of the interval $I$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff1c220",
   "metadata": {},
   "source": [
    "## Homogeneous Equations\n",
    "Now we will deal with the homogeneous linear equation in more detail\n",
    "\n",
    "$$\n",
    "    \\label{eq:lin_homo}\n",
    "    \\dot{\\vc x}={\\tn A}(t)\\vc x.\n",
    "$$\n",
    "\n",
    "However, without specifying the initial condition, this equation has more (even infinitely many) solutions for which the principle of superposition applies.\n",
    "Let $\\vc x(t)$ and $\\vc y(t)$ be two solutions of the homogeneous system\n",
    "then the function $\\vc z(t)=\\alpha\\vc x(t) + \\beta\\vc y(t)$ for any real numbers, $\\alpha$, $\\beta$, is\n",
    "the solutino as well. Indeed:\n",
    "\n",
    "$$\n",
    "   \\dot{\\vc z} = \\alpha\\dot{\\vc x} + \\beta\\dot{\\vc y} = \\alpha\\tn A \\vc x + \\beta \\tn A \\vc y \n",
    "   = \\tn A (\\alpha\\vc x + \\beta\\vc y)\n",
    "$$\n",
    "\n",
    "where we first used the linearity of the derivative and then the linearity of the matrix multiplication. \n",
    "\n",
    "It follows that the set of solutions of the homogeneous system\n",
    "forms the [vector space of functions](https://en.wikipedia.org/wiki/Vector_space#Function_spaces) on the interval $I$. For each vector of initial conditions $\\vc \\xi \\in \\Real^n$ we get exactly one solution.\n",
    "Thus, the solution space also has dimension $n$. The following theorem follows from these observations.\n",
    "\n",
    "**Theorem**\n",
    "Let the matrix function $\\tn A(t)$ and the vector function $\\vc b(t)$ be continuous on the open interval $I$.\n",
    "Then the set\n",
    "${\\mathcal V}(I)$ of all solutions of homogeneous ODE system, defined on the entire interval $I$,\n",
    "form an $n$-dimensional vector space.\n",
    "\n",
    "\n",
    "In particular, it is good to note that the zero function, $\\vc x(t) = \\vc 0$ for all $t\\in I$ , is also a solution and is also a zero element of the solution space. Furthermore, in each $n$-dimensional vector space, we can choose an $n$ element basis, i.e. the set of linearly independent vectors generating this vector space.\n",
    "\n",
    "## Fundamental Solution System\n",
    "\n",
    "**Definition**\n",
    "We say that a vector functions\n",
    "\n",
    "$$\n",
    "\\label{eq:base_solution}\n",
    "\\vc v_1 =\n",
    "\\begin{pmatrix}\n",
    "    v_{11}\\\\ v_{12}\\\\ \\vdots\\\\ v_{1n}\n",
    "\\end{pmatrix},\n",
    "\\quad\n",
    "\\vc v_2 =\n",
    "\\begin{pmatrix}\n",
    "    v_{21}\\\\ v_{22}\\\\ \\vdots\\\\ v_{2n}\n",
    "\\end{pmatrix},\n",
    "\\quad\n",
    "\\dots,\n",
    "\\quad\n",
    "\\vc v_n =\n",
    "\\begin{pmatrix}\n",
    "    v_{n1}\\\\ v_{n2}\\\\ \\vdots\\\\ v_{nn}\n",
    "\\end{pmatrix},\n",
    "\\quad\n",
    "$$\n",
    "\n",
    "form the *fundamental system* of the homogeneous system of ODEs\n",
    "if the functions $\\vc v_1$, $\\vc v_2$, $\\dots$, $\\vc v_n$ are\n",
    "linearly independent solutions on the interval $I$. Tah means that  $\\vc v_1$, $\\vc v_2$, $\\dots$, $\\vc v_n$\n",
    "is a [basis](https://en.wikipedia.org/wiki/Basis_(linear_algebra)) of the linear space $\\mathcal V$.\n",
    "\n",
    "The *fundamental matrix* (matrix function) is formed by the basis in the columns, i.e.\n",
    "\n",
    "$$\n",
    "    {\\tn V}(t) =\n",
    "    \\begin{pmatrix}\n",
    "        v_{11}(t) & \\dots& v_{n1}(t)\\\\\n",
    "        \\vdots& \\ddots &\\\\\n",
    "        v_{1n}(t) & \\dots& v_{nn}(t)\n",
    "    \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Any solution to the homogeneous system \n",
    "then can be written as a linear combination of elements of the base, i.e.\n",
    "\n",
    "$$\n",
    "  \\label{eq:general_shape}\n",
    "  \\vc x(t) = c_1 \\vc v_1(t) + c_2 \\vc v_2(t) + \\dots + c_n\\vc v_n(t) = \\tn V(t) \\vc c.\n",
    "$$\n",
    "\n",
    "Let's clarify what it means that the elements of the basis, i.e. the vector functions \n",
    "$\\vc v_1(t), \\dots, \\vc v_n(t)$, are [linearly independent](https://en.wikipedia.org/wiki/Linear_independence). \n",
    "That means, if a linear combination\n",
    "\n",
    "$$\n",
    "  \\vc v(t) = c_1 \\vc v_1(t) + c_2 \\vc v_2(t) + \\dots + c_n\\vc v_n(t) = \\tn V(t) \\vc c\n",
    "$$\n",
    "\n",
    "is the zero function then the vector $\\vc c \\in \\Real^n$ is the zero vector. Since $\\vc v_i(t)$ is a basis, \n",
    "every solution, i.e. every element of $\\mathcal V$ can be represented:\n",
    "\n",
    "## Properties of fundamental matrices\n",
    "\n",
    "**Theorem**\n",
    "Let $\\tn V(t)$ be the fundamental matrix of the homogeneous system\n",
    "defined on the interval $I$. Then:\n",
    "\n",
    "1. $\\dot{\\tn V}(t) = {\\tn A}(t){\\tn V}(t)$ for all $t\\in I$.\n",
    "1. $\\tn V(t)$ is an [invertible matrix](https://en.wikipedia.org/wiki/Invertible_matrix) (also called non-singular or regular matrix) for all $t\\in I$.\n",
    "1. If ${\\tn C}$ is an invertible real constant matrix of type $n \\times n$, then also\n",
    "   the matrix function ${\\tn W}(t) = {\\tn V}(t) {\\tn C}$ is a fundamental matrix\n",
    "   of the \\eqref{eq:lin_homo} system.\n",
    "\n",
    "**Proof:**\n",
    "The first statement is just other formulation of the fundamental matrix definition. The columns of the matrix \n",
    "$\\tn V(t)$ are solutions of the homogeneous system.\n",
    "Derivation on the left-hand side and matrix multiplication on the right-hand side \n",
    "of the system are applied separately for the each column.\n",
    "\n",
    "The second statemnt follows from the uniquenes of the solution on the interval $I$. Suppose that $\\tn V(t)$ is\n",
    "singular for particular $t$, then there must exist nonzero vector $\\vc c$ for which $v(t) = \\tn V(t) \\vc c $ is zero. So the same problem with reversed time and zero initial condition have at least two solutions $v(-t)$ and the constant zero function.\n",
    "\n",
    "The third statement describes the transition to another basis of the solution space $\\mathcal V(I)$.\n",
    "It is necessary to prove that the columns of the matrix $\\tn W(t)$ also form a fundamental system.\n",
    "These columns are linear combinations of the columns of the original fundamental matrix $\\tn V(t)$ so \n",
    "they are solution as well. We only have to show they are linearly independent.\n",
    "But this follows from the fact that the matrix $\\tn C$ is invertible.\n",
    "For any linear combination $\\vc c$ we have\n",
    "\n",
    "$$\n",
    "   \\tn W(t) \\vc c = \\tn V(t) \\tn C \\vc c = \\tn V(t) \\tilde{\\vc c}.\n",
    "$$\n",
    "Since $\\tn C$ is invertible the vector $\\tilde{\\vc c}$ is zero if and only if $\\vc c = \\vc 0$.\n",
    "\n",
    "Non-singularity of $\\tn V(t)$ is also equivalent to $det(\\tn V(t)) \\ne 0$. For this [determinant](https://en.wikipedia.org/wiki/Determinant)\n",
    "we have:\n",
    "\n",
    "\n",
    "**Theorem**[Liouville's theorem]\n",
    "\n",
    "Let $\\tn V(t)$ be the fundamental matrix of the homogeneous system \n",
    "defined on the interval $I$. Then it applies\n",
    "$$\n",
    "\\det{\\tn V}(t) = (\\det{\\tn V}(\\tau)) \\exp \\Big( \\int\\limits_\\tau^t {\\mathrm tr} \\tn A(s) \\d s \\Big),\n",
    "\\qquad {\\mathrm tr} \\tn A = \\sum\\limits_{i=1}^n a_{ii}\n",
    "$$\n",
    "for all $t, \\tau\\in I$. For proof see [Wikipedia](http://en.wikipedia.org/wiki/Liouville%27s_formula).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f37e17",
   "metadata": {},
   "source": [
    "## Standard Fundamental System\n",
    "From any fundamental matrix $\\tn V(t)$ every solution can be written as:\n",
    "\n",
    "$$\n",
    "    \\vc v(t) = \\tn V(t) \\vc c \n",
    "$$\n",
    "\n",
    "for some vector $\\vc c$ in $\\Real^n$, however there is the unique *standard fundamental matrix* (SFM) $\\tn U(t, \\tau)$ for which\n",
    "this coefficient vector is just the initial condition of the solution, i.e. $\\vc c = \\vc v(\\tau) = \\vc \\xi$.\n",
    "\n",
    "To find the standard fundamental matix, let any fundamental matrix $\\tn V(t)$ be given.\n",
    "To find $\\vc c$ for given $\\vc \\xi$ we calculate:\n",
    "\n",
    "$$\n",
    "\\vc c = \\tn V(\\tau)^{-1} \\vc \\xi,\\quad \\vc v(t) = \\Big[ \\tn V(t) \\tn V(\\tau)^{-1} \\Big] \\xi\n",
    "$$\n",
    "\n",
    "So the standard fundamental matrix can be obtained as:\n",
    "\n",
    "$$\n",
    "    \\tn U(t, \\tau) = \\tn V(t) \\tn V^{-1}(\\tau)\n",
    "$$\n",
    "\n",
    "for any fundamental matrix $\\tn V(t)$. Th columns of SFM form the standard fundamental system, that is the basis of the solution space formed by solutions $\\vc x(t; \\tau, \\vc e_i)$ with the base vectors $\\vc e_i$ of $\\Real^n$ as the initial conditions.\n",
    "\n",
    "We also call $\\tn U(t, \\tau)$ the *transition matrix* as its multiplication realizes transition of a solution from the initial time $\\tau$ to other time $t$. The standard fundamental matrix has all properties of the general fundamental matrices, but have a few interesting properties on its own:\n",
    "\n",
    "**Theorem**\n",
    "Let ${\\tn U}(t,\\tau)$ be the standard fundamental matrix of the homogeneous system:\n",
    "\n",
    "$$\n",
    "    \\dot{\\vc x} = {\\tn A}(t)\\vc x,\n",
    "$$\n",
    "\n",
    "for $t, \\tau\\in I$. Then:\n",
    "\n",
    "1. ${\\tn U}(\\tau,\\tau)$ is the identity matrix for all $\\tau\\in I$.\n",
    "1. ${\\tn U}(t,\\tau){\\tn U}(\\tau,s)={\\tn U}(t,s)$ for all $t, \\tau, s\\in I$ .\n",
    "1. $[{\\tn U}(t,\\tau)]^{-1}={\\tn U}(\\tau,t)$ for all $t, \\tau\\in I$.\n",
    "\n",
    "**Proof:**\n",
    "1. Column $i$ of the matrix $\\tn U(\\tau, \\tau)$ is the solution $\\vc x( \\cdot; \\tau, \\vc e_i)$ in time $\\tau$ where it satisfies the initial condition:\n",
    "$$\n",
    "    \\vc x(\\tau; \\tau, \\vc e_i) = \\vc e_i.\n",
    "$$\n",
    "This vector has one only on row $i$, i.e. the matrix $\\tn U(\\tau, \\tau)$ has ones only on the diagonal, zeros elsewhere.\n",
    " \n",
    "1. For any $\\vc \\xi \\in \\Real^n$ we have\n",
    "$$\n",
    "    \\tn U(t,s) \\vc \\xi =\n",
    "    \\vc x(t;s, \\xi) = \\vc x(t; \\tau, \\vc x(\\tau; s, \\vc \\xi)) =\n",
    "    \\tn U(t,\\tau) \\vc x(\\tau; s, \\vc \\xi) =\n",
    "    \\tn U(t, \\tau) \\tn U(\\tau, s) \\vc \\xi\n",
    "$$\n",
    "\n",
    "1. It follows from points 1) and 3):\n",
    "\n",
    "$$\n",
    "    U(\\tau, t) U(t, \\tau) = U(\\tau, \\tau) = \\tn I\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ad329",
   "metadata": {},
   "source": [
    "## Inhomogeneous Equations\n",
    "\n",
    "Solving inhomogeneous systems of first-order linear ODEs can be done similarly to the variation of constans \n",
    "for scalar ODE. Let us briefly recall the procedure for a scalar equation:\n",
    "\n",
    "$$\n",
    "  \\label{eq:simple_nehom}\n",
    "  \\dot{x} = a(t)x + b(t), \\qquad x(\\tau) = \\xi.\n",
    "$$\n",
    "\n",
    "For the equation, we first determine the solution $x_h(t)$ of the homogeneous equation. We get a one-dimensional vector solution space\n",
    "\n",
    "$$\n",
    "   x(t) = x_h(t) \\xi.\n",
    "$$\n",
    "\n",
    "Next, we look for *particular solution* using the variation of constants, i.e. in the form $x_p(t) = c(t) x_h(t)$.\n",
    "We plug it into the equation:\n",
    "\n",
    "$$\n",
    "   \\dot{ x_p }(t) = \\dot{c}(t) x_h(t) \\quad \\underbrace{+\\dot{x}_h(t) - a(t) x_h(t)}_{=0}\\ = b(t)\n",
    "$$\n",
    "\n",
    "and so\n",
    "\n",
    "$$\n",
    "   x_p(t) = x_h(t) \\int_\\tau^t b(s) x_h^{-1} (s) \\d s.\n",
    "$$\n",
    "\n",
    "Instead of a definite integral, we could use an indefinite integral with an arbitrary constant of integration,\n",
    "but thus the particular solution is zero at the origin, $x_p(\\tau) = 0$. Thanks to this, the entire solution of the inhomogeneous equation is  the sum of the homogeneous and the particulate solution:\n",
    "\n",
    "$$\n",
    "   x(t) = x_h(t) \\xi + x_p(t).\n",
    "$$\n",
    "\n",
    "Now we shall apply the same procedure to an inhomogeneous system of linear ODEs. The overall solution has the form:\n",
    "\n",
    "$$\n",
    "   \\vc x(t; \\tau, \\vc \\xi) = \\tn U(t, \\tau) \\xi + \\vc x_p(t; \\tau, \\vc 0)\n",
    "$$\n",
    "\n",
    "where $\\tn U(t,\\tau)$ is the standard fundamental matrix for the corresponding homogeneous equation and $\\vc x_p$ is the particular solution of the inhomogeneous system for the zero intial vector which can be found in the form:\n",
    "\n",
    "$$\n",
    "   \\vc x_p(t; \\tau, \\vc 0) = \\tn U(t, \\tau) \\int_\\tau^t \\big( \\tn U(s,\\tau)\\big)^{-1} \\vc b(s) \\d s =\n",
    "   \\int_\\tau^t \\tn U(t, s) \\vc b(s).\n",
    "$$\n",
    "\n",
    "For the second equality, just put everything under the integral and use the properties of the standard fundamental matrix:\n",
    "\n",
    "$$\n",
    "   \\tn U(t, \\tau) \\big(\\tn U(s,\\tau) \\big)^{-1} = \\tn U(t,\\tau) \\tn U(\\tau,s) = \\tn U(t,s).\n",
    "$$\n",
    "\n",
    "These preliminary considerations allow us to state the following:\n",
    "\n",
    "\n",
    "**Theorem**\n",
    "Let the matrix function ${\\tn A}$ and the vector function $\\vc b$ be continuous on\n",
    "some open interval $I$ and let $\\tau \\in I$ be arbitrary. Then the initial value problem?\n",
    "\n",
    "$$\n",
    "    \\dot{\\vc x} = {\\tn A}(t)\\vc x+\\vc b(t),\\qquad \\vc x(\\tau)=\\vc\\xi\n",
    "$$\n",
    "\n",
    "for $\\xi \\in \\Real^n$ has exactly one solution that is on the entire interval\n",
    "$I$ in the form:\n",
    "\n",
    "$$\n",
    "    \\vc x(t;\\tau,\\vc\\xi) = {\\tn U}(t,\\tau)\\vc\\xi+\\int_\\tau^t{\\tn U}(t,s) \\vc b( s)\\d s,\\qquad t\\in I.\n",
    "$$\n",
    "\n",
    "**Proof:**\n",
    "The theorem is easiest to prove by direct calculation. For the left-hand side of the equation, we have:\n",
    "\n",
    "\\begin{align*}\n",
    "   \\dot{\\vc x}(t) &= \\tn A(t) \\tn U(t,\\tau) \\vc \\xi +\\tn U(t,t) \\vc b(t) \n",
    "                     + \\int_\\tau^t \\prtl_t{\\tn U}(t,s) \\vc b(s) \\d s\\\\\n",
    "                  &= \\tn A(t) \\tn U(t,\\tau) \\vc \\xi + \\vc b(t) + \\int_\\tau^t \\tn A(t)\\tn U(t,s) \\vc b(s) \\d s\\\\\n",
    "                  &= \\tn A(t) x(t) + b(t),\n",
    "\\end{align*}\n",
    "\n",
    "where at the first line we have used the formula:\n",
    "\n",
    "$$\n",
    "   \\frac{\\d}{\\d t} \\int_\\tau^t f(t,s) \\d s = f(t,t) + \\int_\\tau^t \\prtl_t f(t,s) \\d s.\n",
    "$$\n",
    "\n",
    "It remains to verify the initial condition:\n",
    "\n",
    "$$\n",
    "   \\vc x(\\tau;\\tau, \\vc \\xi) = {\\tn U}(\\tau, \\tau) \\vc \\xi + \\vc 0 = \\vc \\xi.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81203d",
   "metadata": {},
   "source": [
    "Note: has to be corrected yet from here ....\n",
    "\n",
    "## Systems with constant coefficients\n",
    "\\label{const_coef}\n",
    "% solutions using eigenvalues, mention of powers and Putzer's method\n",
    "% ? solve particularly complex eigenvalues?\n",
    "\n",
    "\\todo{Mention of the Putzer and Power method and why we proceed in detail through eigenvectors ...}\n",
    "\n",
    "Next, we will focus on the case of homogeneous linear systems with constants\n",
    "coefficients, i.e. a system that can be written in the form\n",
    "\n",
    "$$\n",
    "    \\label{eq:const_coef}\n",
    "    \\dot{\\vc x} = {\\tn A}\\vc x,\n",
    "$$\n",
    "\n",
    "where $\\tn A$ is a constant real square matrix.\n",
    "\n",
    "Since the constant matrix function $\\tn A(t)=\\tn A$ is continuous for all $t\\in \\Real$, the Cauchy problem has\n",
    "\n",
    "$$\n",
    "    \\label{eq:cauchy_const_coef}\n",
    "    \\dot{\\vc x} = {\\tn A}\\vc x,\\qquad \\vc x(\\tau)=\\vc\\xi\n",
    "$$\n",
    "\n",
    "for each starting point $(\\tau,\\vc\\xi)\\in \\Real\\times \\Real^n$ exactly one solution\n",
    "$\\vc x(t;\\tau,\\vc\\xi)$ defined for all times $t\\in \\Real$.\n",
    "\n",
    "Since the matrix $\\tn A$ does not depend on time, the solution will look the same for any initial instant $\\tau$. For the solution $\\vc x(\\cdot;\\tau, \\vc \\xi)$\n",
    "Cauchy problems \\eqref{eq:cauchy_const_coef} and solutions $x(\\cdot; 0, \\vc \\xi)$ Cauchy problems\n",
    "\n",
    "$$\n",
    "   \\dot{\\vc x} = {\\tn A}\\vc x,\\qquad \\vc x(0)=\\vc\\xi\n",
    "$$\n",
    "\n",
    "applies\n",
    "\n",
    "$$\n",
    "   \\vc x(t;\\tau, \\vc \\xi) = \\vc x(t - \\tau; 0, \\xi),\n",
    "$$\n",
    "\n",
    "since in both cases it is a solution in time $t - \\tau$ from the initial condition. The consequence is a simpler structure of the standard fundamental matrices:\n",
    "\n",
    "**Proposition**\n",
    "\n",
    "For the standard fundamental matrix $\\tn U(t,\\tau)$ the equation \\eqref{eq:const_coef}\n",
    "applies\n",
    "\n",
    "$$\n",
    "   {\\tn U}(t,\\tau)={\\tn U}(t-\\tau,0),\\qquad \\text{for all }t,\\tau\\in \\Real.\n",
    "$$\n",
    "\n",
    "Next, we will show how to find the SFM for equations with constant coefficients.\n",
    "\n",
    "**Proposition**\n",
    "\\label{prop:one_solution}\n",
    "Let $\\vc u\\ne \\vc 0$ be the eigenvector corresponding to the eigenvalue $\\lambda$ of the matrix $\\tn A$, i.e. it holds\n",
    "\n",
    "$$\n",
    "  \\tn A \\vc u = \\lambda \\vc u.\n",
    "$$\n",
    "\n",
    "Then is a vector function\n",
    "\n",
    "$$\n",
    "\\vc v(t)=\\vc u e^{\\lambda t},\\qquad t\\in \\Real,\n",
    "$$\n",
    "\n",
    "by solving the system \\eqref{eq:const_coef}.\n",
    "\n",
    "**Proof:**\n",
    "We perform the proof by substituting into the equation:\n",
    "\n",
    "$$\n",
    "  \\dot{\\vc v}(t) = \\lambda \\vc u e^{\\lambda t} = \\tn A \\vc u e^{\\lambda t} = \\tn A \\vc v(t).\n",
    "$$\n",
    "\n",
    "### Algebraic side note\n",
    "The eigenvalues ​​$\\lambda_i$, $i=1,\\dots, m$ of the real matrix $\\tn A$ are the roots of the characteristic polynomial $p(\\lambda) = \\det(\\tn A-\\lambda I)$.\n",
    "This polynomial with real coefficients generally has $n$ complex roots if we count each root $\\lambda_i$ in its multiplicity $r_i$, i.e. $\\sum_i r_i = n$ holds.\n",
    "For every complex root there is a root that is complexly associated.\n",
    "\n",
    "For every invertible matrix $\\tn A$ there exists an invertible matrix $\\tn P$ such that\n",
    "$$\n",
    "   \\label{eq:Jdecay}\n",
    "   \\tn A = \\tn P \\tn J \\tn P^{-1},\n",
    "$$\n",
    "where $\\tn J$ is the so-called [Jordan normal form](https://en.wikipedia.org/wiki/Jordan_normal_form). \n",
    "Jordan form $\\tn J$ has on the diagonal the eigennumbers of the matrix $\\tn A$ in their respective multiplicities, or it may have ones in some places in the first subdiagonal, and zeroes elsewhere.\n",
    "If the Jordan form has any ones in the first subdiagonal, we say that the matrix $\\tn A$ is \\df{defective}.\n",
    "\n",
    "If $\\tn J$ is a diagonal matrix, we say that $\\tn A$ is diagonalizable. In that case, for each eigenvalue $\\lambda_i$ there is a space of eigenvectors of dimension $r_i$.\n",
    "Thus, for each eigenvalue, one can find $r_i$ vectors that form the basis of the corresponding eigenvalue\n",
    "own subspace. In total, we get $n$ linearly independent eigenvectors\n",
    "$\\vc u_j$ belonging to the eigenvalues ​​$\\lambda_j$, $j=1,\\dots, n$. So these vectors satisfy the equations:\n",
    "\n",
    "$$\n",
    "   \\tn A \\vc u_j = \\lambda_j \\vc u, \\qquad \\text{ for all } j=1,\\dots, n.\n",
    "$$\n",
    "\n",
    "For the matrix $\\tn P$ in the Jordan decomposition \\eqref{eq:Jdecomposition} one can use any matrix that has $n$ linearly independent eigenvectors of the matrix $\\tn A$ in its columns, since\n",
    "\n",
    "$$\n",
    "    \\big( \\tn A \\tn P \\big)_{\\cdot, j} = \\lambda_j \\tn P_{\\cdot, j} = \\big(\\tn P \\tn J\\big)_{\\cdot, j }\n",
    "$$\n",
    "\n",
    "If some $k$-fold eigenvalue has less than $k$ linearly independent eigenvectors, it is a defective matrix $\\tn A$- In that case\n",
    "it is more difficult to find the fundamental matrix, and from a practical point of view it is better to use, for example, Putzer's method (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe8fa90",
   "metadata": {},
   "source": [
    "## Putzer method\n",
    "\n",
    "**Theorem**\n",
    "Let $\\lambda_1, \\lambda_2,\\dots,\\lambda_n$ be all eigenvalues ​​of the matrix\n",
    "$\\tn A$ written in any order, where each eigenvalue is\n",
    "written in sequence as many times as its multiplicity.\n",
    "\n",
    "Let us construct a sequence of $n$ matrices\\\\\n",
    "${\\tn P}_0 = {\\tn E}$, where $\\tn E$ is the identity matrix,\\\\\n",
    "${\\tn P}_1 = ({\\tn A}- \\lambda_1{\\tn E}){\\tn P}_0 = {\\tn A}- \\lambda_1{\\tn E}$,\\\\\n",
    "\\dots\\\\\n",
    "${\\tn P}_j = ({\\tn A}- \\lambda_j{\\tn E}){\\tn P}_{j-1} = ({\\tn A}- \\lambda_j{\\tn E}) ({\\tn A}- \\lambda_{j-1}{\\tn E})\\cdots({\\tn A}- \\lambda_1{\\tn E})$,\\\\\n",
    "\\dots\\\\\n",
    "${\\tn P}_{n-1} = ({\\tn A}- \\lambda_{n-1}{\\tn E}){\\tn P}_{n-2} = ({\\tn A }- \\lambda_{n-1}{\\tn E})({\\tn A}- \\lambda_{n-2}{\\tn E})\\cdots({\\tn A}- \\lambda_1{\\tn E })$,\\\\\n",
    "and a sequence of $n$ functions $q_j(t)$ that are solutions of $n$ Cauchy problems\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcll}\n",
    "\\dot q_1&=&\\lambda_1q_1,&q_1(0)=1,\\\\\n",
    "\\dot q_2&=&\\lambda_2q_2+q_1,&q_2(0)=0,\\\\\n",
    "\\dots\\\\\n",
    "\\dot q_j&=&\\lambda_jq_j+q_{j-1},&q_j(0)=0,\\\\\n",
    "\\dots\\\\\n",
    "\\dot q_n&=&\\lambda_nq_n+q_{n-1},&q_n(0)=0.\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Then the matrix\n",
    "\n",
    "$$\n",
    "{\\tn U}(t) = q_1(t){\\tn P}_0+q_2(t){\\tn P}_1+\\dots+q_n(t){\\tn P}_{n-1}, ~ ~~~t\\in R\n",
    "$$\n",
    "\n",
    "is the standard fundamental matrix of the Cauchy problem\n",
    "\n",
    "$$\\label{4.2.5}\n",
    "\\dot{\\vc x} = {\\tn A}\\vc x, \\vc x(0)=\\vc\\xi.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a533e2",
   "metadata": {},
   "source": [
    "\n",
    "## Metoda rozvoje v mocninnou řadu\n",
    "\n",
    "**Theorem**\n",
    "Standardní fundamentální matici ${\\tn U}(t)$ soustavy \n",
    "$\\dot{\\vc x}={\\tn A}\\vc x$ lze psát ve tvaru\n",
    "\n",
    "$$\n",
    "{\\tn U}(t) = {\\tn E}+{\\tn A}t+\\frac{({\\tn A}t)^2}{2!}+\\dots+\\frac{({\\tn A}t)^k}{k!}+\\dots=\\sum_{k=0}^\\infty\\frac{({\\tn A}t)^k}{k!}, ~~~~t\\in R\n",
    "$$\n",
    "\n",
    "**Proof:**\n",
    "Pro takto definovanou matici $\\tn U$ zřejmě platí ${\\tn U}(0)={\\tn E}$. Pro \n",
    "její derivaci platí\n",
    "\\begin{eqnarray*}\n",
    "\\dot{\\tn U}(t) &=& {\\tn A}+{\\tn A}^2t+\\frac{{\\tn A}^3t^2}{2!}+\\dots+\\frac{{\\tn A}^kt^{k-1}}{(k-1)!}+\\dots=\\\\\n",
    "&=&{\\tn A}\\sum_{k=0}^\\infty\\frac{({\\tn A}t)^k}{k!}={\\tn A}{\\tn U}(t),\\quad t\\in R\n",
    "\\end{eqnarray*}\n",
    "${\\tn U}(t)$ je tedy standardní fundamentální matice uvedené soustavy.\\\\\n",
    "\n",
    "Z tvrzení minulé věty je patrné, proč se pro standardní fundamentální matici \n",
    "používá také symbol $\\mathrm{e}^{{\\tn A}t}$.\n",
    "\n",
    "**Theorem**\n",
    "Matice ${\\tn A}$ vyhovuje své charakteristické rovnici, tedy\n",
    "\n",
    "$$\n",
    "{\\tn A}^n+c_1{\\tn A}^{n-1}+\\dots+c_{n-1}{\\tn A}+c_n{\\tn E}=0,\n",
    "$$\n",
    "\n",
    "kde\n",
    "\n",
    "$$\n",
    "\\det({\\tn A}-\\lambda{\\tn E}) = (-1)^n (\\lambda^n+c_1\\lambda^{n-1}+\\dots+c_{n-1}\\lambda+c_n) = 0\n",
    "$$\n",
    "\n",
    "je charakteristická rovnice matice $\\tn A$.\n",
    "\n",
    "Z minulé věty vyplývá, že matice ${\\tn A}^n$ je lineární kombinací matic $\\tn E$,\n",
    "$\\tn A$, ${\\tn A}^2$, \\dots, ${\\tn A}^{n-1}$. To znamená, že existují funkce \n",
    "$b_0(t)$, $b_1(t)$, \\dots, $b_{n-1}(t)$ takové, že platí\n",
    "\n",
    "$$\n",
    "\\mathrm{e}^{{\\tn A}t} = {\\tn U}(t) = b_0(t){\\tn E}+b_1(t){\\tn A}+\\dots+b_{n-1}(t){\\tn A}^{n-1}, ~~~~t\\in R.\n",
    "$$\n",
    "\n",
    "Uvědomme si, že také každé vlastní číslo $\\lambda_i$ matice $\\tn A$ splňuje její \n",
    "charakteristickou rovnici, a tedy platí \n",
    "\n",
    "$$\n",
    "\\lambda_i^n+c_1\\lambda_i^{n-1}+\\dots+c_{n-1}\\lambda_i+c_n=0,\n",
    "$$\n",
    "\n",
    "a tedy $\\lambda_i^n$ zkombinujeme z hodnot $1$, $\\lambda_i$, $\\lambda_i^2$, \n",
    "\\dots, $\\lambda_i^{n-1}$, stejnými koeficienty, jako jsme získali ${\\tn A}^n$ \n",
    "kombinací matic $\\tn E$, $\\tn A$, ${\\tn A}^2$, \\dots, ${\\tn A}^{n-1}$. \n",
    "Proto bude také platit\n",
    "\n",
    "$$\n",
    "\\mathrm{e}^{\\lambda_it}=\\sum_{k=0}^\\infty\\frac{(\\lambda_it)^k}{k!} = \n",
    "b_0(t) +b_1(t)\\lambda_i+\\dots+b_{n-1}(t)\\lambda_i^{n-1}, ~~~~t\\in R,\n",
    "$$\n",
    "\n",
    "kde $b_0$, $b_1$, \\dots, $b_n$ jsou totožné s funkcemi $b_0$, $b_1$, \\dots, \n",
    "$b_n$ ze vztahu (\\ref{4.5.4}).\n",
    "\n",
    "Má-li tedy matice $\\tn A$ $n$ navzájem různých vlastních čísel $\\lambda_1$, \n",
    "$\\lambda_2$, \\dots, $\\lambda_n$, pak funkce $b_0$, $b_1$, \\dots, $b_n$ můžeme\n",
    "hledat jako řešení soustavy $n$ lineárně nezávislých algebraických rovnic \n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "b_0(t) +b_1(t)\\lambda_1+\\dots+b_{n-1}(t)\\lambda_1^{n-1}&=&\\mathrm{e}^{\\lambda_1t},\\\\\n",
    "b_0(t) +b_1(t)\\lambda_2+\\dots+b_{n-1}(t)\\lambda_2^{n-1}&=&\\mathrm{e}^{\\lambda_2t},\\\\\n",
    "\\dots\\\\\n",
    "b_0(t) +b_1(t)\\lambda_n+\\dots+b_{n-1}(t)\\lambda_n^{n-1}&=&\\mathrm{e}^{\\lambda_nt}.\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Má-li tedy matice $\\tn A$ některé vlastní číslo $\\lambda_i$ vícenásobné, \n",
    "dosazujeme pro něj do předchozí soustavy kromě vztahu (\\ref{4.5.6}) také jeho \n",
    "derivace podle proměnné $\\lambda_i$ (tolik, aby rovnic příslušejících $\\lambda_i$ \n",
    "bylo tolik, kolik je jeho násobnost - označme ji $k$). $k$ rovnic pro \n",
    "$\\lambda_i$ pak bude mít tvar\n",
    "\n",
    "$$\n",
    "\\begin{array}{rrcl}\n",
    "b_0(t) +b_1(t)\\lambda_i+\\dots+&b_{n-1}(t)\\lambda_i^{n-1}&=&\\mathrm{e}^{\\lambda_it},\\\\\n",
    "        b_1(t)+\\dots+&(n-1)b_{n-1}(t)\\lambda_i^{n-2}&=&t\\mathrm{e}^{\\lambda_it},\\\\\n",
    "\\dots\\\\\n",
    "(k-1)!b_{k-1}(t)\\lambda_i+\\dots+&(n-k)\\cdots(n-1)b_{n-1}(t)\\lambda_i^{n-k-1}&=&t^{k-1}\\mathrm{e}^{\\lambda_it}.\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Sestavíme-li soustavu rovnic takto pro každé vlastní číslo, dostaneme systém $n$\n",
    "lineárně nezávislých algebraických rovnic pro $n$ neznámých funkcí $b_0$, $b_1$, \n",
    "\\dots, $b_n$. Po jejím vyřešení a dosazení do rovnice (\\ref{4.5.4}) dostaneme\n",
    "hledanou standardní fundamentální matici.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef1b931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d21a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
